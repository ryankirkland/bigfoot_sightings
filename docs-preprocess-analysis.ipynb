{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decrypting cryptid\n",
    "\n",
    "## Tools, technologies, & techniques featured in this notebook\n",
    "- List TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import svd\n",
    "# import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text ingestion\n",
    "**Source selection**\n",
    "- Observation data was imported from the file you provided. We looked for other sources, but found that the publishers of this information took the most care to be most credible. A team of researchers would follow up on each sighting with an interview and collection of 'evidence' and attempt to consistently classify the report. They only publish the top three tiers of credibility--A through C in order of most to least evidence.\n",
    "\n",
    "**Data import and data wrangling**\n",
    "\n",
    "- 'Beautiful Soup' module to get the html data into a usable format\n",
    "- Data was pretty messy--think of looking through a filing cabinet for a document where the person who was in charge of filing didn't reliably put files in the right folders\n",
    "- Straightened out the filing cabinet and then obtained year and month, state and county, \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing functions and methods\n",
    "- Machine learning models need to have text converted into a format that they can use. \n",
    "- The steps we took to turn the text into machine-readable 'data' included stripping punctuation, tokenizing, lemmatization, and removing stopwords.\n",
    "- We then 'vectorized' each observation so that the models could compare them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/salvir1/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet = WordNetLemmatizer()\n",
    "# porter = PorterStemmer()\n",
    "# snowball = SnowballStemmer('english')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_punc(string:str) -> str:\n",
    "    '''Given a string, removes all punctuation and returned punctuation-less string'''\n",
    "    return re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(str):\n",
    "    '''\n",
    "    Tokenize a str and return a tokenized list.\n",
    "    '''\n",
    "    return [word for word in word_tokenize(str)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(doc):\n",
    "    '''Takes in a doc and lemmatizes tokens in doc\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc: list of tokens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lemmatized tokens\n",
    "    '''\n",
    "    return [wordnet.lemmatize(tkn) for tkn in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rm_stop_words(doc, stops=set(stopwords.words('english'))):\n",
    "    '''Takes in a doc and removes stop words\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc: list of tokens\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Tokens with stop words removed\n",
    "    '''\n",
    "    return([w for w in doc if w not in stops])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(content):\n",
    "    '''\n",
    "    Add docstring. Make flexible to allow for doing, or not doing, preprocessing functions. \n",
    "    Parameters\n",
    "    ----------\n",
    "    content (str): a collection of strings\n",
    "    Returns\n",
    "    -------\n",
    "    A list of lists: each list contains a tokenized version of the original string\n",
    "    '''\n",
    "    preprocessed = []\n",
    "    for i in range(len(content)):\n",
    "        step_1 = remove_punc(content[i].lower())\n",
    "        step_2 = tokenize(step_1)\n",
    "        step_3 = lemmatize(step_2)\n",
    "        step_4 = rm_stop_words(step_3)\n",
    "        preprocessed.append(step_4)\n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading bigfoot data\n",
    "sightings_df = pd.read_csv('data/bigfoot_with_county.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sightings_df['observations'] = sightings_df['observations'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing--data load and function calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tokenized = preprocess_corpus(sightings_df['observations']) # cleaned and tokenized\n",
    "\n",
    "str_cleaned_tokenized = [\" \".join(x) for x in cleaned_tokenized] # string version of cleaned and tokenized "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4411"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Bag of words function'\n",
    "vect = CountVectorizer(max_features=500)\n",
    "word_counts = vect.fit_transform(str_cleaned_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12824608, 0.0759244 , 0.07095224, ..., 0.        , 0.0518886 ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.03951046, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.06966028,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.04487746, ..., 0.02769821, 0.        ,\n",
       "        0.03032734],\n",
       "       [0.        , 0.        , 0.        , ..., 0.20376512, 0.03449167,\n",
       "        0.03187238],\n",
       "       [0.        , 0.        , 0.        , ..., 0.15761544, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfvect = TfidfVectorizer(max_features=500)\n",
    "tfidf_vectorized = tfidfvect.fit_transform(str_cleaned_tokenized)\n",
    "tfidf_vectorized.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering with K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = 5\n",
    "kmeans = KMeans(n_clusters=clusters, \n",
    "                random_state=0).fit(tfidf_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Investigate the clusters  \n",
    "\n",
    "> - Investigate the 'centroids' to find out what \"topics\" Kmeans has discovered by mapping these vectors back into the 'word space'.  Think of each feature/dimension of the centroid vector as representing the \"average\" article or the average occurrences of words for that cluster.\n",
    "   \n",
    "> - Find the features/dimensions with the greatest representation in the centroid.  Print out the top ten words for each centroid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "track print wa inch snow footprint foot found toe area trail picture one long creek large road size human went like would could made \n",
      "\n",
      "wa creature saw tree large back foot area tall river seen looked dog house said wood one like heard ran around walking see two \n",
      "\n",
      "wa heard sound like scream night loud sounded noise time tent wood area howl dog back camp could one animal hear around went never \n",
      "\n",
      "wa road saw car driving side creature foot tall see looked hair back like dark around front seen large right highway home area could \n",
      "\n",
      "wa back saw like tree see could foot time wood would one around looked something area heard got friend thing went didnt never house \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def Sort(sub_li): \n",
    "    return sorted(sub_li, key = lambda x: x[0], reverse=True)\n",
    "\n",
    "def get_word(centroid):\n",
    "    return [x[1] for x in centroid]\n",
    "\n",
    "for k in range(5):\n",
    "    matched = zip(kmeans.cluster_centers_[k], tfidfvect.get_feature_names())\n",
    "    match = Sort(list(matched))\n",
    "    print(' '.join(get_word(match[:24])), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For heirarchical clustering methods, see 819 am clustering assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity\n",
    "- Unsupervised learning\n",
    "\n",
    "- Use the cosine similarity to compare similarity between documents.\n",
    "\n",
    "- sklearn's [linear_kernel](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.linear_kernel.html) (computes dot product) can be used on tfidf to compute the cosine similarity since rows are normalized.*\n",
    "\n",
    "- Here's a page on cosine similarity from [sklearn documentation](http://scikit-learn.org/stable/modules/metrics.html#cosine-similarity) and a relevant [stack overflow post](http://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity).\n",
    "\n",
    "- *The stack overflow post is helpful. It provides instruction over how to slice the tfidf and then how to apply cosine similarity between one doc and all of the rest.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = linear_kernel(tfidf_vectorized[1:2], tfidf_vectorized[1:500]).flatten() # This is comparing cs for article #2 and the next 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0 134 299  51  35]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.41648761, 0.40048277, 0.39099911, 0.38874647])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_docs_indices = cosine_similarities.argsort()[:-6:-1] # This identifies the index of the top 5 most similar.\n",
    "print(related_docs_indices)\n",
    "\n",
    "most_similar = cosine_similarities[related_docs_indices] # and their related cs\n",
    "most_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I and two of my friends were bored one night so we decided to do a little snowmachining. Though it was illegal to snowmachine in Anchorage, there were some good trails to ride on a little north of my house.  We took off at probably 11 pm, rode up the road about a quarter mile, and cut off on the trails. It had snowed about 10 inches a few days before so there was fresh snow, with no tracks.  I was leading the way for about a half hour, then we stopped and talked for a little bit.  We took off again and kept cruising on some sort of game trail that led to an opening in the woods.  I rode off into the opening with my friends following about fifty yards behind me.  I came over this little mound and saw strange tracks leading to this spot in the snow where it looked like something had pushed aside some snow and layed down.  I figured it was just a moose or something.  But I followed the tracks over the next small hill and as I came down the far side my headlight pointed right on the back of a bigfoot.  It was only about 10 to 12 feet in front of me.  It was running in the opposite direction.  I slammed on the brakes because I was scared out of my mind.  It continued to run away, jumped over a dead log covered in snow and disappeared into a group of trees and into the darkness.  I was so surprised and scared I quickly turned around and rode back toward my friends. I met them back by the first mound and said \"We need to get out of here,\"  and rode back towards my house.  When I told them about it back near my house, they laughed and told me it was probably a bear or someone in the woods.  But I was 100% positive that is was not a bear or anything else. The way it was running through the deep snow made me sure that it wasn't anything human.  For a long time I was made fun of and everyone told me I was crazy so I didn't like talking about it.  \n",
      "I live in Kansas City Mo the year was 1983 some friends and I went on a backpacking outing in Arkansas just across the border from Missouri close to Fayettville Ark about 20 miles east of town.The area was very wooded with lots of hills and valleys on our second day there about 3 miles from our camp we came across 3 nest they were about 8 foot long oval shaped nest I call them nest because they were made from rocks positioned in a oval pattern and the inside filled with leaves and beside 2 of these nest there were large tree branches cleaned of bark slick we stood around looking at them a few minutes when someone yelled come look at this doody the pile that was there was huge we guessed maybe bear stuff but ive never seen bear stuff but the hair stood up on my neck we left walked about a mile when we came upon a pine tree the bark had been striped off it I mean like something climbed to the top sunk in its fingernails and slid down peeling it off in strips 15 ft long we stayed 2 more days heard many spooky noises but never saw anything \n",
      "Near Cresent City: a television production crew from Los Angeles videotapes what appears to be a bigfoot crossing a forest road in front of their RV. Among the crew was a Playboy model who subsequently appeared on the Jay Leno show and Hardcopy to discuss the incident.Sent to the Internet Virtual Bigfoot Conference (IVBC) mailing list: The \"Redwoods Footage\"\n",
      "One evening my wife and I decided to go to my hunting club property to a place where we used to go sit and talk. We got there just before dark and had been there for several hours when it happened. The place where we were is on a large power transmission line right of way.There is a small stream that crosses the clearing, and a very steep hill on the side where we parked. In fact, so steep that it is difficult to drive a four wheel drive down to the stream. On the other side of the stream there is a low level spot that then becomes another steep hill. I would say that the hills are a good 50 feet higher than the stream.I had parked my truck on the hilltop, and we sat on the tailgate facing the stream. Around 11:00 pm we heard a very loud snorting noise coming from the bottom of the hill, and the sound of brush moving and breaking. I thought that it was a wild hog, because they are plentiful in this area, so I told my wife to get in the truck, because I was afraid it would attack us. She got in the truck while I tried to find my flashlight and my gun.When she slammed the door, I heard a loud, low growl/grunt and it sounded like something large started running up the hill towards us. I was standing in the bed of my truck by now trying to shine my light down the hill, but the batteries were weak and I couldn't see very far.There was a very bright moon out so I turned off my light, and could see a large shadow moving around about halfway up the hill towards us.I was listening to it move around and make the same growl/grunt noise. I could also hear what sounded like breathing noises.I then caught scent of a strange, musky, sour odor and heard more brush breaking and what sounded like stomping noises. I was certain by now that this was not a wild hog, but couldn't figure out what it might be. So I told my wife to start my truck and rev the engine a few times and when she did, I heard what sounded like something crashing through the brush heading down hill and moving fast. We were both a little spooked by now so we left.As I pulled out onto the dirt road off the power line trail, I turned toward the bridge that crosses the small stream (the road roughly parallels the power line) a large number of deer ran at high speed across the road,heading away from the stream.I tried to convince myself that it was just deer that I heard,but couldn't explain the shadow I saw. \n",
      "It was April of 2011. My son, daughter-in-law, wife and I had been over at my in-laws having dinner. My son and his wife and their infant son had recently moved in with us. We were in the process of adding a new laundry room and garage on the back side of our house. When we came in from next door my son and his family were ahead of my wife and me by a minute or two. I noticed the lights to the new addition were on and figured that one of them had gone out to retrieve their laundry. I opened the back door and said is anyone out there. I didnt yell so I thought they might not have heard me. I stepped out on the patio and started walking toward the garage that didnt have a door hung yet. As I did I saw a dark figure at the back of our SUV. It scared me that there was someone in, or had just passed through our garage. Without saying another word I ran back into the house to get my 410 shotgun and let me son know to join me outside. This only took 30 seconds or less. I went back out but this time I was yelling if there is someone out there you better speak up or I am going to shoot you. My son joined me and we ran out into the yard both yelling for the person to identify themselves. We circled our house and saw nothing. It had rained earlier in the afternoon and evening and as we came back to re-enter our house confident that what I had seen ran away we noticed footprints on the concrete patio deck. These footprints at first looked like that of foot gloves people that fit each toe like a glove does the hand. But the thing that was conspicuous was the size. They were enormous. Not only long but wide, huge like that of what an NBA star might leave. (I say that because I have a pair of shoes owned by an NBA star that my nephew gave me who is on an NBA coaching staff.) My point, these were very large feet and very wide strides. It then dawned on me how large the figure I saw in the garage had to be. As stated I own an SUV and at the back part of the garage where I saw the figure the concrete starts to slope down from the garage. This figure I saw was head and shoulders over the top of the SUV and he (it) was already on the slope because he was not inside the garage when I saw him. I joked to my son and later to my family; you know that thing I saw that night was big enough to be a Sasquatch. We all laughed because we had not heard of any other Bigfoot sightings in lower Alabama. Then your show comes to television and I go on your site today and learn that there was indeed a Bigfoot sighting on Ft. Rucker back in the 90s by a solder. I live just five to six miles from the post. Im not convinced that what I saw should be reported to you but I do know that if it was a person I never want to see them again on a dark night in my yard because they are a very big person. Our house is in a rual country setting in Pinckard, AL with limited neighbors.  \n"
     ]
    }
   ],
   "source": [
    "for i in related_docs_indices:\n",
    "    print(sightings_df['observations'].iloc[i]) # Going step by step pulling up the most similar reports by index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompositions NMF (and SVD)\n",
    "- Unsupervised learning\n",
    "- Good for situations when there's some potentially valid grouping to both rows and columns, such as putting Joe and Sam in the same group because they like similar movies (as opposed to traditional supervised models where there are features and targets)\n",
    "- See 820pm solution to NMF for good soft classification and test of classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "- Supervised learning method to assign class probabilities to a document\n",
    "- See 818PM NLP-pipeline-programming-net-example for using sklearn Naive Bayes classifier. See also 818PM lecture on text classification. Solutions to assignment contain a number of useful naive Bayes python functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "counties = pd.read_csv('data/US_FIPS_Codes.csv', header=1)\n",
    "counties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
